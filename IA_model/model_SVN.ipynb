{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4096b503",
   "metadata": {},
   "source": [
    "# Imports required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c95ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import io\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from unittest.mock import patch\n",
    "from nbformat import read\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.signal import butter, filtfilt, iirnotch\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a36eadb",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "601ff561",
   "metadata": {},
   "source": [
    "### Execution of the ipynb file and recovery of the 5 discriminating parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bbfe0238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook 1Nmar.ipynb imported successfully.\n",
      "Notebook 2Nmar.ipynb imported successfully.\n",
      "Notebook 3Nmar.ipynb imported successfully.\n",
      "Notebook 4Nmar.ipynb imported successfully.\n",
      "Notebook 5Nmar.ipynb imported successfully.\n",
      "Notebook 6Nmar.ipynb imported successfully.\n",
      "Notebook 7Nmar.ipynb imported successfully.\n",
      "Notebook 8Nmar.ipynb imported successfully.\n",
      "Notebook 9Nmar.ipynb imported successfully.\n",
      "Notebook 10Nmar.ipynb imported successfully.\n",
      "Notebook 11Nmar.ipynb imported successfully.\n",
      "Notebook 1Amar.ipynb imported successfully.\n",
      "Notebook 2Amar.ipynb imported successfully.\n",
      "Notebook 3Amar.ipynb imported successfully.\n",
      "Notebook 4Amar.ipynb imported successfully.\n",
      "Notebook 5Amar.ipynb imported successfully.\n",
      "Notebook 6Amar.ipynb imported successfully.\n",
      "Notebook 7Amar.ipynb imported successfully.\n",
      "Notebook 8Amar.ipynb imported successfully.\n",
      "Notebook 9Amar.ipynb imported successfully.\n",
      "Notebook 10Amar.ipynb imported successfully.\n",
      "Notebook 11Amar.ipynb imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# List of .ipynb files to process for Normal and Patient analyses\n",
    "notebook_files_N = [f\"{i}Nmar.ipynb\" for i in range(1, 12)]\n",
    "notebook_files_A = [f\"{i}Amar.ipynb\" for i in range(1, 12)]\n",
    "\n",
    "# Dictionary to store results\n",
    "results = {}\n",
    "\n",
    "# Process Normal analysis notebooks\n",
    "for file_name in notebook_files_N:\n",
    "    try:\n",
    "        # Load the .ipynb file\n",
    "        with open(\"../Normal_analyse/\" + file_name, 'r', encoding='utf-8') as f:\n",
    "            notebook = read(f, as_version=4)\n",
    "        print(f\"Notebook {file_name} imported successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the file is not found\n",
    "        print(f\"Error: The file '{file_name}' was not found. Please ensure it exists in the current directory.\")\n",
    "        continue\n",
    "\n",
    "    # Dictionary to store variables from the notebook\n",
    "    global_vars = {}\n",
    "\n",
    "    # Backup stdout and stderr to suppress output\n",
    "    stdout_backup = sys.stdout\n",
    "    stderr_backup = sys.stderr\n",
    "    sys.stdout = io.StringIO()  # Capture standard output\n",
    "    sys.stderr = io.StringIO()  # Capture errors\n",
    "\n",
    "    # Disable interactive Matplotlib display\n",
    "    plt.ioff()\n",
    "\n",
    "    # Override `plt.show()` and `display()` to suppress displays\n",
    "    with patch(\"matplotlib.pyplot.show\"), patch(\"IPython.display.display\"):\n",
    "        # Execute all code cells without displaying output\n",
    "        for cell in notebook.cells:\n",
    "            if cell.cell_type == \"code\":\n",
    "                exec(cell.source, global_vars)\n",
    "\n",
    "    # Restore normal output\n",
    "    sys.stdout = stdout_backup\n",
    "    sys.stderr = stderr_backup\n",
    "    plt.ion()  # Re-enable interactive display\n",
    "    plt.close(\"all\")  # Close all figures in memory\n",
    "\n",
    "    # Retrieve variables from the notebook\n",
    "    se_RF = global_vars.get(\"se_RF\", \"Variable not found\")\n",
    "    se_BF = global_vars.get(\"se_BF\", \"Variable not found\")\n",
    "    se_VS = global_vars.get(\"se_VM\", \"Variable not found\")\n",
    "    se_ST = global_vars.get(\"se_ST\", \"Variable not found\")\n",
    "    mf_ST = global_vars.get(\"mf_ST\", \"Variable not found\")\n",
    "\n",
    "    # Store the retrieved variables in the results dictionary\n",
    "    results[\"SE_RF_\" + file_name] = se_RF\n",
    "    results[\"SE_BF_\" + file_name] = se_BF\n",
    "    results[\"SE_VS_\" + file_name] = se_VS\n",
    "    results[\"SE_ST_\" + file_name] = se_ST\n",
    "    results[\"MF_ST_\" + file_name] = mf_ST\n",
    "\n",
    "# Process Patient analysis notebooks\n",
    "for file_name in notebook_files_A:\n",
    "    try:\n",
    "        # Load the .ipynb file\n",
    "        with open(\"../Patient_analyse/\" + file_name, 'r', encoding='utf-8') as f:\n",
    "            notebook = read(f, as_version=4)\n",
    "        print(f\"Notebook {file_name} imported successfully.\")\n",
    "    except FileNotFoundError:\n",
    "        # Handle the case where the file is not found\n",
    "        print(f\"Error: The file '{file_name}' was not found. Please ensure it exists in the current directory.\")\n",
    "        continue\n",
    "\n",
    "    # Dictionary to store variables from the notebook\n",
    "    global_vars = {}\n",
    "\n",
    "    # Backup stdout and stderr to suppress output\n",
    "    stdout_backup = sys.stdout\n",
    "    stderr_backup = sys.stderr\n",
    "    sys.stdout = io.StringIO()  # Capture standard output\n",
    "    sys.stderr = io.StringIO()  # Capture errors\n",
    "\n",
    "    # Disable interactive Matplotlib display\n",
    "    plt.ioff()\n",
    "\n",
    "    # Override `plt.show()` and `display()` to suppress displays\n",
    "    with patch(\"matplotlib.pyplot.show\"), patch(\"IPython.display.display\"):\n",
    "        # Execute all code cells without displaying output\n",
    "        for cell in notebook.cells:\n",
    "            if cell.cell_type == \"code\":\n",
    "                exec(cell.source, global_vars)\n",
    "\n",
    "    # Restore normal output\n",
    "    sys.stdout = stdout_backup\n",
    "    sys.stderr = stderr_backup\n",
    "    plt.ion()  # Re-enable interactive display\n",
    "    plt.close(\"all\")  # Close all figures in memory\n",
    "\n",
    "    # Retrieve variables from the notebook\n",
    "    se_RF = global_vars.get(\"se_RF\", \"Variable not found\")\n",
    "    se_BF = global_vars.get(\"se_BF\", \"Variable not found\")\n",
    "    se_VS = global_vars.get(\"se_VM\", \"Variable not found\")\n",
    "    se_ST = global_vars.get(\"se_ST\", \"Variable not found\")\n",
    "    mf_ST = global_vars.get(\"mf_ST\", \"Variable not found\")\n",
    "\n",
    "    # Store the retrieved variables in the results dictionary\n",
    "    results[\"SE_RF_\" + file_name] = se_RF\n",
    "    results[\"SE_BF_\" + file_name] = se_BF\n",
    "    results[\"SE_VS_\" + file_name] = se_VS\n",
    "    results[\"SE_ST_\" + file_name] = se_ST\n",
    "    results[\"MF_ST_\" + file_name] = mf_ST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d416ad2",
   "metadata": {},
   "source": [
    "### Creating groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "662fd762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SE_RF: {'SE_RF_1Nmar.ipynb': 5.990737103074829, 'SE_RF_2Nmar.ipynb': 6.317456432929115, 'SE_RF_3Nmar.ipynb': 6.440423251824849, 'SE_RF_4Nmar.ipynb': 6.352179204367657, 'SE_RF_5Nmar.ipynb': 6.5920083988334905, 'SE_RF_6Nmar.ipynb': 6.703081761245851, 'SE_RF_7Nmar.ipynb': 6.084548812741607, 'SE_RF_8Nmar.ipynb': 6.69234345740482, 'SE_RF_9Nmar.ipynb': 6.266350660804018, 'SE_RF_10Nmar.ipynb': 6.509200151026221, 'SE_RF_11Nmar.ipynb': 5.6555372343495085, 'SE_RF_1Amar.ipynb': 6.828890613563787, 'SE_RF_2Amar.ipynb': 5.67042665049945, 'SE_RF_3Amar.ipynb': 8.118408707896174, 'SE_RF_4Amar.ipynb': 7.8649819620895665, 'SE_RF_5Amar.ipynb': 7.840377651143833, 'SE_RF_6Amar.ipynb': 8.078310976897322, 'SE_RF_7Amar.ipynb': 6.159596094841848, 'SE_RF_8Amar.ipynb': 5.8708232184323785, 'SE_RF_9Amar.ipynb': 8.22933817189336, 'SE_RF_10Amar.ipynb': 7.984544312521164, 'SE_RF_11Amar.ipynb': 8.031416893007746}\n",
      "SE_BF: {'SE_BF_1Nmar.ipynb': 6.18689966869902, 'SE_BF_2Nmar.ipynb': 6.640285559619914, 'SE_BF_3Nmar.ipynb': 6.839215561448629, 'SE_BF_4Nmar.ipynb': 6.469742716091036, 'SE_BF_5Nmar.ipynb': 6.613671531116735, 'SE_BF_6Nmar.ipynb': 6.728851200105053, 'SE_BF_7Nmar.ipynb': 6.759418031276338, 'SE_BF_8Nmar.ipynb': 7.002329654800817, 'SE_BF_9Nmar.ipynb': 6.5333329167017045, 'SE_BF_10Nmar.ipynb': 6.637463819559299, 'SE_BF_11Nmar.ipynb': 6.480087786511514, 'SE_BF_1Amar.ipynb': 7.104006698978839, 'SE_BF_2Amar.ipynb': 7.263403846404013, 'SE_BF_3Amar.ipynb': 8.664391491629898, 'SE_BF_4Amar.ipynb': 8.594079726841645, 'SE_BF_5Amar.ipynb': 8.580716719201547, 'SE_BF_6Amar.ipynb': 8.66954665214736, 'SE_BF_7Amar.ipynb': 7.445064297008544, 'SE_BF_8Amar.ipynb': 7.118195540395973, 'SE_BF_9Amar.ipynb': 8.334571575853218, 'SE_BF_10Amar.ipynb': 8.100458694131735, 'SE_BF_11Amar.ipynb': 7.893401843914746}\n",
      "SE_VS: {'SE_VS_1Nmar.ipynb': 5.9181926734938894, 'SE_VS_2Nmar.ipynb': 6.220895746303275, 'SE_VS_3Nmar.ipynb': 6.288452984014685, 'SE_VS_4Nmar.ipynb': 6.37927751328983, 'SE_VS_5Nmar.ipynb': 6.391608903511729, 'SE_VS_6Nmar.ipynb': 6.543641324957765, 'SE_VS_7Nmar.ipynb': 5.834287667187746, 'SE_VS_8Nmar.ipynb': 5.614547787463324, 'SE_VS_9Nmar.ipynb': 6.295794489549753, 'SE_VS_10Nmar.ipynb': 6.375501380622903, 'SE_VS_11Nmar.ipynb': 4.820155413741227, 'SE_VS_1Amar.ipynb': 6.410050908096065, 'SE_VS_2Amar.ipynb': 6.064699891373323, 'SE_VS_3Amar.ipynb': 7.148239408479313, 'SE_VS_4Amar.ipynb': 7.7841986874851195, 'SE_VS_5Amar.ipynb': 7.850360324386405, 'SE_VS_6Amar.ipynb': 8.457864715650961, 'SE_VS_7Amar.ipynb': 5.665937637453756, 'SE_VS_8Amar.ipynb': 6.100188473187572, 'SE_VS_9Amar.ipynb': 7.831112914584177, 'SE_VS_10Amar.ipynb': 7.757961765486671, 'SE_VS_11Amar.ipynb': 6.561214130989011}\n",
      "SE_ST: {'SE_ST_1Nmar.ipynb': 6.365287942992718, 'SE_ST_2Nmar.ipynb': 6.306886172407419, 'SE_ST_3Nmar.ipynb': 6.627788823048001, 'SE_ST_4Nmar.ipynb': 6.829070295298429, 'SE_ST_5Nmar.ipynb': 6.5742818885989065, 'SE_ST_6Nmar.ipynb': 6.838418965094658, 'SE_ST_7Nmar.ipynb': 7.193851893258983, 'SE_ST_8Nmar.ipynb': 6.664795364243654, 'SE_ST_9Nmar.ipynb': 6.290014656940733, 'SE_ST_10Nmar.ipynb': 6.426300696837062, 'SE_ST_11Nmar.ipynb': 6.712005123962548, 'SE_ST_1Amar.ipynb': 7.245091244288623, 'SE_ST_2Amar.ipynb': 7.212343598285846, 'SE_ST_3Amar.ipynb': 8.65154270125122, 'SE_ST_4Amar.ipynb': 9.216149413848418, 'SE_ST_5Amar.ipynb': 8.927854611611258, 'SE_ST_6Amar.ipynb': 9.146020617220582, 'SE_ST_7Amar.ipynb': 7.702985088411534, 'SE_ST_8Amar.ipynb': 6.837653074175864, 'SE_ST_9Amar.ipynb': 8.515201123731686, 'SE_ST_10Amar.ipynb': 8.211614755452562, 'SE_ST_11Amar.ipynb': 8.33027590673341}\n",
      "MF_ST: {'MF_ST_1Nmar.ipynb': 83.29321977241379, 'MF_ST_2Nmar.ipynb': 62.29543050718941, 'MF_ST_3Nmar.ipynb': 84.92617309461518, 'MF_ST_4Nmar.ipynb': 99.60246903336706, 'MF_ST_5Nmar.ipynb': 82.04283254364202, 'MF_ST_6Nmar.ipynb': 94.68702454124661, 'MF_ST_7Nmar.ipynb': 111.51950100648911, 'MF_ST_8Nmar.ipynb': 77.93836249202414, 'MF_ST_9Nmar.ipynb': 79.01801929306289, 'MF_ST_10Nmar.ipynb': 85.10408102542928, 'MF_ST_11Nmar.ipynb': 107.78195284910353, 'MF_ST_1Amar.ipynb': 85.68286461443513, 'MF_ST_2Amar.ipynb': 87.88601937185668, 'MF_ST_3Amar.ipynb': 105.69251822855297, 'MF_ST_4Amar.ipynb': 126.74225520603522, 'MF_ST_5Amar.ipynb': 124.77680229385132, 'MF_ST_6Amar.ipynb': 130.38708915801905, 'MF_ST_7Amar.ipynb': 108.75857505537456, 'MF_ST_8Amar.ipynb': 77.28886193619695, 'MF_ST_9Amar.ipynb': 126.72014124558741, 'MF_ST_10Amar.ipynb': 115.67303798045546, 'MF_ST_11Amar.ipynb': 109.86791546188503}\n"
     ]
    }
   ],
   "source": [
    "# Initialize empty dictionaries to store results for each parameter\n",
    "SE_RF = {}\n",
    "SE_BF = {}\n",
    "SE_VS = {}\n",
    "SE_ST = {}\n",
    "MF_ST = {}\n",
    "\n",
    "# Iterate through the results dictionary and check if the key correspond to a specific dictionary\n",
    "for key, value in results.items():\n",
    "    if \"SE_RF\" in key:\n",
    "        SE_RF[key] = value\n",
    "    elif \"SE_BF\" in key:\n",
    "        SE_BF[key] = value\n",
    "    elif \"SE_VS\" in key:\n",
    "        SE_VS[key] = value\n",
    "    elif \"SE_ST\" in key:\n",
    "        SE_ST[key] = value\n",
    "    elif \"MF_ST\" in key:\n",
    "        MF_ST[key] = value\n",
    "\n",
    "# Print the dictionaries to verify the results\n",
    "print(\"SE_RF:\", SE_RF)\n",
    "print(\"SE_BF:\", SE_BF)\n",
    "print(\"SE_VS:\", SE_VS)\n",
    "print(\"SE_ST:\", SE_ST)\n",
    "print(\"MF_ST:\", MF_ST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44cca3fb",
   "metadata": {},
   "source": [
    "### Creating the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fd0a01b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SE_RF     SE_BF     SE_VS     SE_ST       MF_ST Group\n",
      "0   6.828891  7.104007  6.410051  7.245091   85.682865     A\n",
      "1   6.084549  6.759418  5.834288  7.193852  111.519501     N\n",
      "2   6.159596  7.445064  5.665938  7.702985  108.758575     A\n",
      "3   8.078311  8.669547  8.457865  9.146021  130.387089     A\n",
      "4   5.870823  7.118196  6.100188  6.837653   77.288862     A\n",
      "5   6.592008  6.613672  6.391609  6.574282   82.042833     N\n",
      "6   8.229338  8.334572  7.831113  8.515201  126.720141     A\n",
      "7   5.655537  6.480088  4.820155  6.712005  107.781953     N\n",
      "8   6.317456  6.640286  6.220896  6.306886   62.295431     N\n",
      "9   8.031417  7.893402  6.561214  8.330276  109.867915     A\n",
      "10  5.670427  7.263404  6.064700  7.212344   87.886019     A\n",
      "11  6.440423  6.839216  6.288453  6.627789   84.926173     N\n",
      "12  7.864982  8.594080  7.784199  9.216149  126.742255     A\n",
      "13  6.266351  6.533333  6.295794  6.290015   79.018019     N\n",
      "14  6.509200  6.637464  6.375501  6.426301   85.104081     N\n",
      "15  8.118409  8.664391  7.148239  8.651543  105.692518     A\n",
      "16  7.840378  8.580717  7.850360  8.927855  124.776802     A\n",
      "17  6.352179  6.469743  6.379278  6.829070   99.602469     N\n",
      "18  5.990737  6.186900  5.918193  6.365288   83.293220     N\n",
      "19  6.703082  6.728851  6.543641  6.838419   94.687025     N\n",
      "20  6.692343  7.002330  5.614548  6.664795   77.938362     N\n",
      "21  7.984544  8.100459  7.757962  8.211615  115.673038     A\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame using the values from the dictionaries\n",
    "data = {\n",
    "    \"SE_RF\": list(SE_RF.values()),  # Spectral Entropy for RF\n",
    "    \"SE_BF\": list(SE_BF.values()),  # Spectral Entropy for BF\n",
    "    \"SE_VS\": list(SE_VS.values()),  # Spectral Entropy for VS\n",
    "    \"SE_ST\": list(SE_ST.values()),  # Spectral Entropy for ST\n",
    "    \"MF_ST\": list(MF_ST.values())   # Median Frequency for ST\n",
    "}\n",
    "\n",
    "# Convert the data dictionary into a DataFrame\n",
    "df_parameters = pd.DataFrame(data)\n",
    "\n",
    "# Add a \"Group\" column to differentiate between Normal (N) and Patient (A) groups\n",
    "df_parameters[\"Group\"] = [\"N\"] * 11 + [\"A\"] * 11  # First 11 entries are \"N\", next 11 are \"A\"\n",
    "\n",
    "# Shuffle the rows of the DataFrame randomly and reset the index\n",
    "df_parameters = df_parameters.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "# Print the resulting DataFrame to verify its structure and content\n",
    "print(df_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdaa4ce",
   "metadata": {},
   "source": [
    "### Separating the dataframe into an input X and an output y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1240396",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X :\n",
      "      SE_RF     SE_BF     SE_VS     SE_ST       MF_ST\n",
      "0  6.828891  7.104007  6.410051  7.245091   85.682865\n",
      "1  6.084549  6.759418  5.834288  7.193852  111.519501\n",
      "2  6.159596  7.445064  5.665938  7.702985  108.758575\n",
      "3  8.078311  8.669547  8.457865  9.146021  130.387089\n",
      "4  5.870823  7.118196  6.100188  6.837653   77.288862\n",
      "\n",
      "y :\n",
      "0    A\n",
      "1    N\n",
      "2    A\n",
      "3    A\n",
      "4    A\n",
      "Name: Group, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Define X (features) and y (target)\n",
    "X = df_parameters[[\"SE_RF\", \"SE_BF\", \"SE_VS\", \"SE_ST\", \"MF_ST\"]]  # Extract feature columns\n",
    "y = df_parameters[\"Group\"]  # Extract target column\n",
    "\n",
    "# Display the first few rows of X and y for verification\n",
    "print(\"X :\")\n",
    "print(X.head())\n",
    "print(\"\\ny :\")\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2112fe0",
   "metadata": {},
   "source": [
    "# Comparison of different kernel types for the SVC model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5114882",
   "metadata": {},
   "source": [
    "### Separation between groups to have a train group and a test group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94c508a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of X_train: 17\n",
      "Size of X_test: 5\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "# X_train and X_test contain the features for training and testing, respectively\n",
    "# y_train and y_test contain the target labels for training and testing, respectively\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Print the size of the training and testing sets to verify the split\n",
    "print(\"Size of X_train:\", len(X_train))\n",
    "print(\"Size of X_test:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d62d43b",
   "metadata": {},
   "source": [
    "### Linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2905c926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['N' 'N' 'N' 'N' 'A']\n",
      "Actual values: ['A' 'N' 'N' 'N' 'A']\n",
      "Accuracy: 0.8\n"
     ]
    }
   ],
   "source": [
    "# Create a linear SVC model\n",
    "model_linear = SVC(kernel='linear')\n",
    "\n",
    "# Train the model using the training dataset\n",
    "model_linear.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions_linear = model_linear.predict(X_test)\n",
    "\n",
    "# Print the predictions and the actual values for comparison\n",
    "print(\"Predictions:\", predictions_linear)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy_linear = accuracy_score(y_test, predictions_linear)\n",
    "print(\"Accuracy:\", accuracy_linear)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b560bf",
   "metadata": {},
   "source": [
    "### Polynamial model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b924e0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['N' 'N' 'N' 'A' 'A']\n",
      "Actual values: ['A' 'N' 'N' 'N' 'A']\n",
      "Accuracy: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Create a polynomial SVC model with degree 3\n",
    "model_poly = SVC(kernel='poly', degree=3)\n",
    "\n",
    "# Train the model using the training dataset\n",
    "model_poly.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions_poly = model_poly.predict(X_test)\n",
    "\n",
    "# Print the predictions and the actual values for comparison\n",
    "print(\"Predictions:\", predictions_poly)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy_poly = accuracy_score(y_test, predictions_poly)\n",
    "print(\"Accuracy:\", accuracy_poly)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e3ce7b",
   "metadata": {},
   "source": [
    "### Radial Basis Function model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "029a0273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['N' 'N' 'A' 'A' 'A']\n",
      "Actual values: ['A' 'N' 'N' 'N' 'A']\n",
      "Accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Create an SVC model with an RBF kernel and a gamma value of 0.1\n",
    "model_rbf = SVC(kernel='rbf', gamma=0.1)\n",
    "\n",
    "# Train the model using the training dataset\n",
    "model_rbf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions_rbf = model_rbf.predict(X_test)\n",
    "\n",
    "# Print the predictions and the actual values for comparison\n",
    "print(\"Predictions:\", predictions_rbf)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy_rbf = accuracy_score(y_test, predictions_rbf)\n",
    "print(\"Accuracy:\", accuracy_rbf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f10f62",
   "metadata": {},
   "source": [
    "### Sigmoid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "74374e2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions: ['A' 'A' 'A' 'A' 'A']\n",
      "Actual values: ['A' 'N' 'N' 'N' 'A']\n",
      "Accuracy: 0.4\n"
     ]
    }
   ],
   "source": [
    "# Create an SVC model with a sigmoid kernel\n",
    "model_sigmoid = SVC(kernel='sigmoid')\n",
    "\n",
    "# Train the model using the training dataset\n",
    "model_sigmoid.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions_sigmoid = model_sigmoid.predict(X_test)\n",
    "\n",
    "# Print the predictions and the actual values for comparison\n",
    "print(\"Predictions:\", predictions_sigmoid)\n",
    "print(\"Actual values:\", y_test.values)\n",
    "\n",
    "# Calculate and print the accuracy of the model\n",
    "accuracy_sigmoid = accuracy_score(y_test, predictions_sigmoid)\n",
    "print(\"Accuracy:\", accuracy_sigmoid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522fd4d3",
   "metadata": {},
   "source": [
    "The best models are the one that use a linear kernel because of it accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "040d1af4",
   "metadata": {},
   "source": [
    "# Using models on a given signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df33cd9f",
   "metadata": {},
   "source": [
    "### The EMG signal is loaded and cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d9a24e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         RF        BF        VM        ST    FX   Time\n",
      "0  0.000067  0.001470 -0.000341  0.001915  57.6  0.000\n",
      "1 -0.000860  0.005161 -0.003763  0.005889  57.5  0.001\n",
      "2 -0.000235  0.001298 -0.002438  0.007574  57.3  0.002\n",
      "3  0.000051  0.001652  0.001119  0.005550  57.1  0.003\n",
      "4  0.001938  0.007421  0.005673  0.001038  56.9  0.004\n"
     ]
    }
   ],
   "source": [
    "# Specify the file path for the EMG signal data\n",
    "file_path = '../emg+dataset+in+lower+limb/SEMG_DB1/N_TXT/1Nmar.txt'\n",
    "\n",
    "# Function to load and process the data from the file\n",
    "def load_and_process_data(file_path):\n",
    "    # Read the file and skip the first 6 lines\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        raw_lines = file.read().split('\\n')[6:]\n",
    "\n",
    "    # Keep only lines that resemble numeric data\n",
    "    numeric_lines = [line for line in raw_lines if re.match(r'^[-\\d\\s\\t.eE]+$', line.strip())]\n",
    "\n",
    "    # Join the lines to parse them with pandas\n",
    "    cleaned_content = '\\n'.join(numeric_lines)\n",
    "\n",
    "    # Read the data once to detect the number of columns\n",
    "    temp_df = pd.read_csv(StringIO(cleaned_content), sep=r'\\s+', header=None)\n",
    "    num_columns = temp_df.shape[1]\n",
    "\n",
    "    # Ensure there are at least 5 numeric columns\n",
    "    if num_columns >= 5:\n",
    "        column_names = ['RF', 'BF', 'VM', 'ST', 'FX'] + [f'Extra{i}' for i in range(num_columns - 5)]\n",
    "        usecols = list(range(5))  # Use only the first 5 columns\n",
    "    else:\n",
    "        raise ValueError(f\"The file does not contain enough numeric columns: {num_columns}\")\n",
    "\n",
    "    # Reload the data with the appropriate column names and selected columns\n",
    "    data = pd.read_csv(StringIO(cleaned_content), sep=r'\\s+', header=None, names=column_names, usecols=usecols)\n",
    "    data.dropna(inplace=True)  # Remove rows with missing values\n",
    "    data = data.astype(float)  # Convert all data to float\n",
    "    data['Time'] = data.index / 1000  # Add a 'Time' column based on the index\n",
    "    return data\n",
    "\n",
    "# Function to apply a bandpass filter to the signal\n",
    "def bandpass_filter(data, lowcut=20, highcut=450, fs=1000, order=4):\n",
    "    nyquist = 0.5 * fs  # Nyquist frequency\n",
    "    low = lowcut / nyquist  # Normalize the low cutoff frequency\n",
    "    high = highcut / nyquist  # Normalize the high cutoff frequency\n",
    "    b, a = butter(order, [low, high], btype='band')  # Design the bandpass filter\n",
    "    return filtfilt(b, a, data)  # Apply the filter to the data\n",
    "\n",
    "# Function to apply a notch filter to the signal\n",
    "def notch_filter(data, notch_freq=50, fs=1000, quality_factor=30):\n",
    "    nyquist = 0.5 * fs  # Nyquist frequency\n",
    "    freq = notch_freq / nyquist  # Normalize the notch frequency\n",
    "    b, a = iirnotch(freq, quality_factor)  # Design the notch filter\n",
    "    return filtfilt(b, a, data)  # Apply the filter to the data\n",
    "\n",
    "# Load and process the data from the file\n",
    "data = load_and_process_data(file_path)\n",
    "\n",
    "# Apply filters and normalization to each signal column\n",
    "for col in ['RF', 'BF', 'VM', 'ST']:\n",
    "    data[col] = bandpass_filter(data[col])  # Apply the bandpass filter\n",
    "    data[col] = notch_filter(data[col])  # Apply the notch filter\n",
    "\n",
    "# Take the absolute value of the \"FX\" column\n",
    "data[\"FX\"] = abs(data[\"FX\"])\n",
    "\n",
    "# Print the first few rows of the processed data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64347cbb",
   "metadata": {},
   "source": [
    "### Calculation of discriminant parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1948845f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function transforms a time-domain signal into the frequency domain\n",
    "def transform_signal_to_frequency_domain(data, fs=1000):\n",
    "    # Sampling period\n",
    "    T = 1 / fs  \n",
    "\n",
    "    # Compute the Discrete Fourier Transform (DFT)\n",
    "    X = np.fft.fft(data)\n",
    "\n",
    "    # Compute the associated frequencies\n",
    "    n = len(data)  # Number of samples\n",
    "    frequencies = np.fft.fftfreq(n, T)\n",
    "\n",
    "    # Select positive frequencies for better visualization\n",
    "    positive_frequencies = frequencies[:n // 2]\n",
    "    positive_X = X[:n // 2]\n",
    "\n",
    "    # Compute the amplitude of the frequency-domain signal\n",
    "    amplitude = np.abs(positive_X)\n",
    "\n",
    "    return positive_frequencies, amplitude\n",
    "\n",
    "# Transform the signals into the frequency domain\n",
    "frequencies, amplitude_RF = transform_signal_to_frequency_domain(data['RF'])\n",
    "_, amplitude_BF = transform_signal_to_frequency_domain(data['BF'])\n",
    "_, amplitude_VM = transform_signal_to_frequency_domain(data['VM'])\n",
    "_, amplitude_ST = transform_signal_to_frequency_domain(data['ST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "983cb469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Median Frequency RF: 83.29321977241379\n",
      "Spectral Entropy RF: 5.990737103074829\n",
      "Spectral Entropy BF: 6.18689966869902\n",
      "Spectral Entropy VM: 5.9181926734938894\n",
      "Spectral Entropy ST: 6.365287942992718\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate the median frequency\n",
    "def calcul_mf(frequencies, amplitude):\n",
    "    power = amplitude**2  # Calculate the power spectrum\n",
    "    return np.sum(frequencies * power) / np.sum(power)  # Compute the weighted average of frequencies\n",
    "\n",
    "# Function to calculate spectral entropy\n",
    "def calcul_se(amplitude):\n",
    "    power = amplitude**2  # Calculate the power spectrum\n",
    "    power_sum = np.sum(power)  # Sum of the power spectrum\n",
    "    if power_sum == 0:  # Handle the case where the power sum is zero\n",
    "        return 0\n",
    "    \n",
    "    P = power / power_sum  # Normalize the power spectrum\n",
    "    P_nonzero = P[P > 0]  # Exclude zero values to avoid log(0)\n",
    "\n",
    "    return -np.sum(P_nonzero * np.log(P_nonzero))  # Compute the spectral entropy\n",
    "\n",
    "# Calculate discriminant parameters\n",
    "mf_ST = calcul_mf(frequencies, amplitude_ST)  # Median frequency for the ST signal\n",
    "se_RF = calcul_se(amplitude_RF)  # Spectral entropy for the RF signal\n",
    "se_BF = calcul_se(amplitude_BF)  # Spectral entropy for the BF signal\n",
    "se_VM = calcul_se(amplitude_VM)  # Spectral entropy for the VM signal\n",
    "se_ST = calcul_se(amplitude_ST)  # Spectral entropy for the ST signal\n",
    "\n",
    "# Print the calculated parameters\n",
    "print(\"Median Frequency RF:\", mf_ST)\n",
    "print(\"Spectral Entropy RF:\", se_RF)\n",
    "print(\"Spectral Entropy BF:\", se_BF)\n",
    "print(\"Spectral Entropy VM:\", se_VM)\n",
    "print(\"Spectral Entropy ST:\", se_ST)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74157fbc",
   "metadata": {},
   "source": [
    "### Transformation into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad086b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      SE_RF   SE_BF     SE_VS     SE_ST     MF_ST\n",
      "0  5.990737  6.1869  6.561214  6.365288  83.29322\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame with the calculated discriminant parameters\n",
    "data = {\n",
    "    \"SE_RF\": [se_RF],  # Spectral Entropy for RF\n",
    "    \"SE_BF\": [se_BF],  # Spectral Entropy for BF\n",
    "    \"SE_VS\": [se_VS],  # Spectral Entropy for VS\n",
    "    \"SE_ST\": [se_ST],  # Spectral Entropy for ST\n",
    "    \"MF_ST\": [mf_ST]   # Median Frequency for ST\n",
    "}\n",
    "\n",
    "# Convert the dictionary into a pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Print the resulting DataFrame to verify its structure and content\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ecd1f5",
   "metadata": {},
   "source": [
    "### We use the AI model to determine whether it is a patient or a healthy subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ad9f2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['N']  : No problem detected.\n"
     ]
    }
   ],
   "source": [
    "# Use the linear SVC model to predict the class of the given data\n",
    "result_linear = model_linear.predict(df)\n",
    "\n",
    "# Check the predicted result and print the corresponding message\n",
    "if result_linear == \"N\":  # If the result is \"N\" (Normal)\n",
    "    print(result_linear, \" : No problem detected.\")\n",
    "else:  # If the result is not \"N\" (indicating a problem)\n",
    "    print(result_linear, \" : Problem detected.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MY_HUGO_SAUNIER",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
